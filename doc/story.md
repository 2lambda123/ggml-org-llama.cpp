# Complie

doc/build.md

# model

[prithivMLmods/Llama-Deepsync-1B-GGUF](https://huggingface.co/prithivMLmods/Llama-Deepsync-1B-GGUF)

# Run model

./build/bin/llama-cli -m models/Llama-Deepsync-1B.Q4_K_M.gguf -p "what's your name"

# Specific parameter

cd /home/xunchan/Workspace/llama.xunchan/gguf-py/examples

python reader.py  /home/xunchan/Workspace/llama.xunchan/models/Llama-Deepsync-1B.Q4_K_M.gguf

or

show in [huggingface](https://huggingface.co/) frontend

## general.architecture

llama

## llama

### llama.block_count

### llama.context_length

### llama.embedding_length

### llama.feed_forward_length

### 

#### block