{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def get_oai_response(prompt, model, functions, msgs):\n",
    "  openai.api_key = \"sk-\"\n",
    "  # openai.base_url = \"http://localhost:8019/v1/\"\n",
    "  \n",
    "  try:\n",
    "    completion = openai.chat.completions.create(\n",
    "      model=model,\n",
    "      temperature=0.1,\n",
    "      messages=msgs,\n",
    "      tools=functions,\n",
    "      tool_choice=\"auto\",\n",
    "      # functions=functions,\n",
    "      # function_call=\"auto\",\n",
    "      stream=False,\n",
    "    )\n",
    "    return completion.choices[0]\n",
    "  except Exception as e:\n",
    "    print(e, model, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NVPCmdRCtY9lO7sVhOFRPS6R', function=Function(arguments='{\"location\":\"Boston, MA\",\"unit\":\"f\"}', name='getCurrentWeather'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "functions = [\n",
    "   {\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "   {    \"type\": \"function\",\n",
    "     \"function\":\n",
    "    {\n",
    "        \"name\": \"orderUmbrella\",\n",
    "        \"description\": \"Do this to help user to order an umbrella online\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"brand_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the umbrella brand\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"brand_name\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "]\n",
    "\n",
    "\n",
    "user_query = \"check the weather in boston\"\n",
    "# msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query}, {\"role\": \"function\", \"content\": '<<functions>>[getCurrentWeather(location=\"Boston)]'}, {\"role\": \"observation\", \"content\": \"<<observation>>72 f, rainy.\"}\n",
    "#         ,\n",
    "#         {\"role\": \"assistant\", \"content\": \"The current weather in Boston is 72 degrees Fahrenheit and it's raining. Would you like to order an umbrella?\"},\n",
    "#          {\"role\": \"user\", \"content\": \"yes pls\"},\n",
    "#         ]\n",
    "msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query}]\n",
    "\n",
    "res = get_oai_response(user_query, \"gpt-4-0125-preview\", functions=functions, msgs=msgs)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=0, function=[Function(arguments='{\"location\":\"Boston\",\"unit\":\"c\"}', name='getCurrentWeather')], type='function')]))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def get_mistral_rubra_response(prompt, model, functions, msgs):\n",
    "  openai.api_key = \"sk-\"\n",
    "  openai.base_url = \"http://localhost:8019/v1/\"\n",
    "  \n",
    "  try:\n",
    "    completion = openai.chat.completions.create(\n",
    "      model=model,\n",
    "      temperature=0.1,\n",
    "      messages=msgs,\n",
    "      tools=functions,\n",
    "      tool_choice=\"auto\",\n",
    "      # functions=functions,\n",
    "      # function_call=\"auto\",\n",
    "      stream=False,\n",
    "    )\n",
    "    return completion.choices[0]\n",
    "  except Exception as e:\n",
    "    print(e, model, prompt)\n",
    "\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "functions = [\n",
    "   {\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "   {    \"type\": \"function\",\n",
    "     \"function\":\n",
    "    {\n",
    "        \"name\": \"orderUmbrella\",\n",
    "        \"description\": \"Do this to help user to order an umbrella online\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"brand_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the umbrella brand\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"brand_name\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "]\n",
    "\n",
    "\n",
    "user_query = \"check the weather in boston\"\n",
    "# msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query}, {\"role\": \"function\", \"content\": '<<functions>>[getCurrentWeather(location=\"Boston)]'}, {\"role\": \"observation\", \"content\": \"<<observation>>72 f, rainy.\"}\n",
    "#         ,\n",
    "#         {\"role\": \"assistant\", \"content\": \"The current weather in Boston is 72 degrees Fahrenheit and it's raining. Would you like to order an umbrella?\"},\n",
    "#          {\"role\": \"user\", \"content\": \"yes pls\"},\n",
    "#         ]\n",
    "msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query}]\n",
    "\n",
    "res = get_mistral_rubra_response(user_query, \"gpt-4-0125-preview\", functions=functions, msgs=msgs)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORE the following for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <<functions>>[get_stock_fundermentals(symbol=\"TSLA\")]\n",
      "<<functions>>[get_stock_fundermentals(symbol=\"GOOG\")]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "functions = [\n",
    "    {\"function\":\n",
    "    {\n",
    "        \"name\": \"get_stock_fundermentals\",\n",
    "        \"description\": \"Get the stock fundermentals data\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stock symbol, e.g. AAPL, GOOG\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"symbol\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "    {\"function\":{\n",
    "        \"name\": \"check_word_anagram\",\n",
    "        \"description\": \"Check if two words are anagrams of each other\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"word1\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The first word\"\n",
    "                },\n",
    "                \"word2\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The second word\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"word1\",\n",
    "                \"word2\"\n",
    "            ]\n",
    "        }\n",
    "    }}\n",
    "]\n",
    "\n",
    "user_query = \"What's the stock fundementals of Tesla and google\"\n",
    "\n",
    "# \n",
    "# msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query}, {\"role\": \"function\", \"content\": '<<functions>>[get_stock_price(symbol=\"TSLA\")], <<functions>>[get_stock_price(symbol=\"GOOG\")]'}, {\"role\": \"observation\", \"content\": \"{'symbol': 'TSLA', 'company_name': 'Tesla, Inc.', 'sector': 'Consumer Cyclical', 'industry': 'Auto Manufacturers', 'market_cap': 611384164352, 'pe_ratio': 49.604652, 'pb_ratio': 9.762013, 'dividend_yield': None, 'eps': 4.3, 'beta': 2.427, '52_week_high': 299.29, '52_week_low': 152.37}}\"}]\n",
    "msgs = [{\"role\": \"system\", \"content\":system_prompt} ,{\"role\": \"user\", \"content\": user_query},]\n",
    "res = get_mistral_rubra_response(user_query, \"mistral_rubra\", functions=functions, msgs=msgs)\n",
    "print(res.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: <<functions>>[get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit'), func(x= 1, b='2', c=123)]\n",
      "[\"get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit')\", \" func(x= 1, b='2', c=123))\"]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.pyenv/versions/3.10.12/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3548\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[19], line 40\u001b[0m\n    result_dict = parse_function_call(function_call.strip())\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[19], line 22\u001b[0m in \u001b[1;35mparse_function_call\u001b[0m\n    parsed_value = ast.literal_eval(value)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/.pyenv/versions/3.10.12/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    'Boston\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "content = \"<<functions>>[get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit'), func(x= 1, b='2', c=123)]\"\n",
    "regex = re.compile(r\"<<functions>>\\[(.*?)\\]\", re.DOTALL)\n",
    "matches = re.findall(regex, content)\n",
    "\n",
    "print(\"content:\", content)\n",
    "\n",
    "def parse_function_call(call):\n",
    "    func_name, args_str = call.split('(', 1)\n",
    "    args_str = args_str.rstrip(')')\n",
    "    args_list = args_str.split(',')\n",
    "    args_dict = {}\n",
    "    for arg in args_list:\n",
    "        key, value = arg.split('=')\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        try:\n",
    "            # Use ast.literal_eval to safely parse the string to its Python type\n",
    "            parsed_value = ast.literal_eval(value)\n",
    "        except ValueError as e:\n",
    "            # If parsing fails, keep the original string. \n",
    "            # This might happen if the value is a string that's not quoted as a Python literal.\n",
    "            print(f\"Error parsing value {value}: {e}\")\n",
    "            parsed_value = value\n",
    "        args_dict[key] = parsed_value\n",
    "    return {\"name\": func_name.strip(), \"arguments\": args_dict}\n",
    "\n",
    "result_dicts = []\n",
    "for match in matches:\n",
    "    # Splitting each function call from the match. We add ')' back because it was used as a delimiter\n",
    "    function_calls = [f\"{func})\" for func in match.split('),') if func]\n",
    "    print(function_calls)\n",
    "    for function_call in function_calls:\n",
    "        # Removing the trailing ')' that was added for the last function call\n",
    "        if function_call.endswith(')'):\n",
    "            function_call = function_call[:-1]\n",
    "        result_dict = parse_function_call(function_call.strip())\n",
    "        result_dicts.append(result_dict)\n",
    "    print(result_dicts)\n",
    "\n",
    "res = json.dumps(result_dicts, ensure_ascii=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_current_weather', 'args': [], 'kwargs': {'location': 'Boston, MA', 'api_key': 123456789, 'unit': 'fahrenheit'}}, {'name': 'func', 'args': ['cde'], 'kwargs': {'x': 1, 'b': '2', 'c': [1, 2, {'a': 1, 'b': 2}]}}]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "raw_input_str = \"<<functions>>[get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit'), func('cde', x= 1, b='2', c=[1, 2, {'a': 1, 'b': 2}])]\"\n",
    "# raw_input_str = \"<<functions>>[get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit'), func( x=1, b='2', c=123)]\"\n",
    "input_str = raw_input_str.split('<<functions>>')[1]\n",
    "# Parse the string into an AST\n",
    "parsed_ast = ast.parse(input_str, mode='eval')\n",
    "\n",
    "def find_calls(node):\n",
    "    calls = []\n",
    "    if isinstance(node, ast.Call):  # If it's a function call\n",
    "        calls.append(node)\n",
    "        return calls\n",
    "    for child in ast.iter_child_nodes(node):\n",
    "        calls.extend(find_calls(child))\n",
    "    return calls\n",
    "\n",
    "# Extract all function call nodes\n",
    "calls = find_calls(parsed_ast.body)\n",
    "\n",
    "functions = []\n",
    "for call in calls:\n",
    "    if isinstance(call.func, ast.Name):  # Ensure it's a named function\n",
    "        function_name = call.func.id\n",
    "        args = [ast.literal_eval(arg) for arg in call.args]  # Convert all positional arguments\n",
    "        kwargs = {kw.arg: ast.literal_eval(kw.value) for kw in call.keywords}  # Convert all keyword arguments\n",
    "        functions.append({\"name\": function_name, \"args\": args, \"kwargs\":kwargs})\n",
    "\n",
    "print(functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('get_current_weather', [], {'location': 'Boston, MA', 'api_key': 123456789, 'unit': 'fahrenheit'}), ('func', ['cde'], {'x': 1, 'b': '2', 'c': ['func_nested(1, 2)', {'a': \"func_deep('value')\"}]})]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "input_str = \"[get_current_weather(location='Boston, MA', api_key=123456789, unit='fahrenheit'), func('cde', x= 1, b='2', c=[func_nested(1, 2), {'a': func_deep('value')}])]\"\n",
    "\n",
    "def ast_node_to_object(node):\n",
    "    if isinstance(node, ast.Constant):\n",
    "        return node.value\n",
    "    elif isinstance(node, ast.List):\n",
    "        return [ast_node_to_object(n) for n in node.elts]\n",
    "    elif isinstance(node, ast.Dict):\n",
    "        return {ast_node_to_object(key): ast_node_to_object(value) for key, value in zip(node.keys, node.values)}\n",
    "    elif isinstance(node, ast.Tuple):\n",
    "        return tuple(ast_node_to_object(n) for n in node.elts)\n",
    "    elif isinstance(node, ast.Call):\n",
    "        return ast.unparse(node)\n",
    "        # Handle function calls: convert to a representation with the function name and arguments\n",
    "        # func_name = ast_node_to_object(node.func)  # Get the function name\n",
    "        # args = [ast_node_to_object(arg) for arg in node.args]  # Convert all positional arguments\n",
    "        # kwargs = {kw.arg: ast_node_to_object(kw.value) for kw in node.keywords}  # Convert all keyword arguments\n",
    "        # return {\"function\": func_name, \"args\": args, \"kwargs\": kwargs}\n",
    "    elif isinstance(node, ast.Name):\n",
    "        return node.id  # Return the identifier name\n",
    "    # Add more cases here as needed\n",
    "    return None\n",
    "\n",
    "# Parse the string into an AST\n",
    "parsed_ast = ast.parse(input_str, mode='eval')\n",
    "\n",
    "# Function to find only the top-level Call nodes\n",
    "def find_top_level_calls(node):\n",
    "    calls = []\n",
    "    if isinstance(node, ast.Call):  # If it's a function call\n",
    "        calls.append(node)\n",
    "        # Do not descend into child nodes to ensure we're only capturing top-level calls\n",
    "        return calls\n",
    "    for child in ast.iter_child_nodes(node):\n",
    "        # Recursively find calls without going into nested calls\n",
    "        calls.extend(find_top_level_calls(child))\n",
    "    return calls\n",
    "\n",
    "# Extract all top-level function call nodes\n",
    "top_level_calls = find_top_level_calls(parsed_ast.body)\n",
    "\n",
    "# Process each call node to get the details you want\n",
    "functions = []\n",
    "for call in top_level_calls:\n",
    "    if isinstance(call.func, ast.Name):  # Ensure it's a named function\n",
    "        function_name = call.func.id\n",
    "        args = [ast_node_to_object(arg) for arg in call.args]  # Convert all positional arguments\n",
    "        kwargs = {kw.arg: ast_node_to_object(kw.value) for kw in call.keywords}  # Convert all keyword arguments\n",
    "        functions.append((function_name, args, kwargs))\n",
    "\n",
    "print(functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
